{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc054081",
   "metadata": {},
   "source": [
    "# Load the news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316cbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20f18ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d532de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99e153c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_labels = twenty_train.data, twenty_train.target\n",
    "test, test_labels = twenty_test.data, twenty_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7268fe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows: 2257\n"
     ]
    }
   ],
   "source": [
    "print(\"No of rows:\",len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78d85e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Label: comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))\n",
    "print(\"Label:\",twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e7214",
   "metadata": {},
   "source": [
    "# Convert Text to numbers\n",
    "CountVectorizer: Convert a collection of text documents to a matrix of token counts. <br>\n",
    "Here by doing ‘count_vect.fit_transform(twenty_train.data)’, we are learning the vocabulary dictionary and it returns a Document-Term matrix. [n_samples, n_features].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bf0032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a346c9",
   "metadata": {},
   "source": [
    "# TFIDF\n",
    "TF: Just counting the number of words in each document has 1 issue: it will give more weightage to longer documents than shorter documents. To avoid this, we can use frequency (TF - Term Frequencies) i.e. #count(word) / #Total words, in each document.\n",
    "\n",
    "TF-IDF: Finally, we can even reduce the weightage of more common words like (the, is, an etc.) which occurs in all document. This is called as TF-IDF i.e Term Frequency times inverse document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d395dfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f263cb",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edc5879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133f93a",
   "metadata": {},
   "source": [
    "# Manual text prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9289a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457f8fe",
   "metadata": {},
   "source": [
    "# Accuracy testing of Naivebayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "850a1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8348868175765646\n",
      "[[192   2   6 119]\n",
      " [  2 347   4  36]\n",
      " [  2  11 322  61]\n",
      " [  2   2   1 393]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_labels)\n",
    "\n",
    "X_new_counts = count_vect.transform(test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "y_pred = clf.predict(X_new_tfidf)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "ac = accuracy_score(test_labels,y_pred)\n",
    "print(ac)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616ff37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80470906",
   "metadata": {},
   "source": [
    "# Trying other algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad7f0ae",
   "metadata": {},
   "source": [
    "Lets try SGDClassifier <br><br>\n",
    "SGDClassifier is a linear classifier (by default in sklearn it is a linear SVM) that uses SGD for training (that is, looking for the minima of the loss using SGD). According to the documentation: SGDClassifier is a Linear classifiers (SVM, logistic regression, a.o.) with SGD training.\n",
    "\n",
    "SGDClassifier supports multi-class classification by combining multiple binary classifiers in a “one versus all” (OVA) scheme. For each of the classes, a binary classifier is learned that discriminates between that and all oth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "347e40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c27a9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "clf = sgd_model.fit(X_train_tfidf, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7012575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9101198402130493\n",
      "[[256  11  16  36]\n",
      " [  4 380   3   2]\n",
      " [  5  35 353   3]\n",
      " [  5  11   4 378]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_new_counts = count_vect.transform(test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "y_pred = clf.predict(X_new_tfidf)\n",
    "\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "ac = accuracy_score(test_labels,y_pred)\n",
    "print(ac)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e328cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c48a70ec",
   "metadata": {},
   "source": [
    "Note: You can checkout other models to load from https://scikit-learn.org/stable/supervised_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb30721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
